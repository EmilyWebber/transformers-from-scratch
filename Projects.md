# Project Candidates
After you've stepped through the hands-on lab and have a good understanding of how transformers literally work, its time to apply that knowledge by picking a new project to develop!

## Theoretical vs Applied

### Applied Projects
If you are new to deep learning and/or new to transformers, it's going to be a better move to pick an applied project. Generally speaking, this means you'll be selecting an existing code repository out there from Papers With Code. Read through the paper, try to understand how the model works, look at the performance on the benchmark dataset, then clone the code to your local Studio notebook and try to get it to work! To be really competitive here you'd add something new - a new dataset to fine-tune the base model, a new dataset to simply keep training that model on, your choice.

Optionally, you can try deploying that model to an Alexa skill! 

See the list of potential applied projects below. Generally speaking an applied project is going to index harder on code.

### Theoretical Projects
If you are not new to this space, then we encourage you to stretch your theoretical skills here and try to push forward the state of the art. Can you solve a net new problem space? Can you take an advantage of transformers and apply it to an historical deep learning method, what about the other way around? Can you find a way to improve transformers? What about generic linear models, is there a way we can use transformers to improve them? Can you explore the concept of fairness as it applies to transformers, specificially embeddings?

Whichever project you pick, we'd love to see your mathematical equations, then we want you to walk us through those equations. See the list of potential projects below. Generally speaking a theoretical project is going to index harder on an intellectual framework, rather than code necessarily upfront.

## Going for Baby Yoda
Remember, there are plush Baby Yodas on the line here! Here's what you need to take home that sweet green child.

1. Tell us what you built / are proposing to build.
2. Tell us why it is important
3. Tell us how it works / how it would work.
4. Tell us what research literature it is engaged with
5. Tell us what customer problem it solves.

It's not enough to just answer those questions - you need to raise the bar on how you answer those questions. That means going for detail, pizazz, flair, creativity, promise, novelty, etc. Remember to play to your strengths in your submission content - it's up to you if you want to submit a deck, a written narrative, a notebook, a demo, a video recording, etc. 

We have a limited number of Baby Yodas to give away. You'll be submitting your projects to your MC team, then on to Emily for the final determination. Make sure to send us your mailing address so we can send it to you! 

# Project Candidates


## Applied
1. Pick a learning task from Papers With Code's state-of-the-art repository. Can you get it to work locally? Now can you extend it, by using a different dataset?
- https://paperswithcode.com/sota
2. Transformers for X* problem 
3. Generating X* 
4. Fine-tune transformers from scratch on X dataset.
5. Host a transformer-based model inside an Alexa skill for X problem space
6. Transforming predictive maintenance - what would transformers look like inside of machinery-health prediction problems?

X* refers to your own dataset of choice.


## Theoretical
1. XGTransform - can we apply any concepts to Transformers to gradient boosted trees? Would that help improve our accuracy or train times?
2. Speedy Transformers - is there anyway we can make unsupervised training of transformers faster? What about the fine-tuning?
3. Easy FineTune - the finetuning promise is very attractive, but frequently becomes too hard for your average data scientist to really take advantage of. Can we develop a framework to make this even easier?
4. Transformers for X* problem 
5. Generating X* 
6. Transforming reinforcement learning - can you explore transformers within the context of reinforcement learning?


X* refers to your own dataset of choice.

